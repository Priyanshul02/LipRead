{"cells":[{"cell_type":"markdown","id":"95d37003","metadata":{"id":"95d37003"},"source":["# ğŸ§  Lip Reading CTC Trainer + Inference on Real Video (.mpg + .align)"]},{"cell_type":"code","execution_count":null,"id":"25604824","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"25604824","executionInfo":{"status":"ok","timestamp":1753105952528,"user_tz":-330,"elapsed":13148,"user":{"displayName":"Priyanshul Thakur","userId":"11776131157483549665"}},"outputId":"21824286-a0c7-4ded-a33a-3bb5f83b271e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (4.12.0.88)\n","Collecting mediapipe\n","  Downloading mediapipe-0.10.21-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n","Requirement already satisfied: numpy<2.3.0,>=2 in /usr/local/lib/python3.11/dist-packages (from opencv-python-headless) (2.0.2)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.4.0)\n","Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.3.0)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.2.10)\n","Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.2)\n","Requirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (3.10.0)\n","INFO: pip is looking at multiple versions of mediapipe to determine which version is compatible with other requirements. This could take a while.\n","  Downloading mediapipe-0.10.20-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n","  Downloading mediapipe-0.10.18-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n","  Downloading mediapipe-0.10.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n","  Downloading mediapipe-0.10.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n","Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.11.0.86)\n","Collecting protobuf<5,>=4.25.3 (from mediapipe)\n","  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n","Collecting sounddevice>=0.4.4 (from mediapipe)\n","  Downloading sounddevice-0.5.2-py3-none-any.whl.metadata (1.6 kB)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.0)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.1)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.73.1)\n","Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n","Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n","Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n","Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.7.14)\n","Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8.2)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n","Requirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (1.15.3)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (4.58.5)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.4.8)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (11.2.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (2.9.0.post0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n","Downloading mediapipe-0.10.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.7 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading sounddevice-0.5.2-py3-none-any.whl (32 kB)\n","Installing collected packages: protobuf, sounddevice, mediapipe\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 5.29.5\n","    Uninstalling protobuf-5.29.5:\n","      Successfully uninstalled protobuf-5.29.5\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\n","ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed mediapipe-0.10.14 protobuf-4.25.8 sounddevice-0.5.2\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google"]},"id":"08220fced4324e6583c735cae6a71ffe"}},"metadata":{}}],"source":["!pip install opencv-python-headless mediapipe tensorflow\n"]},{"cell_type":"code","source":["import shutil\n","import os\n","\n","# ğŸš® Delete existing videos folder if present\n","if os.path.exists(\"data/videos\"):\n","    shutil.rmtree(\"data/videos\")\n"],"metadata":{"id":"tkT43WJGsylW"},"id":"tkT43WJGsylW","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"61fc6699","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"61fc6699","executionInfo":{"status":"ok","timestamp":1753113474229,"user_tz":-330,"elapsed":12385,"user":{"displayName":"Priyanshul Thakur","userId":"11776131157483549665"}},"outputId":"92204b4d-010d-4c4b-ebb3-78f098cc7ece"},"outputs":[{"output_type":"stream","name":"stdout","text":["â¬‡ï¸ Downloading data.zip from Google Drive...\n"]},{"output_type":"stream","name":"stderr","text":["Downloading...\n","From (original): https://drive.google.com/uc?id=1YlvpDLix3S-U8fd-gqRwPcWXAXm8JwjL\n","From (redirected): https://drive.google.com/uc?id=1YlvpDLix3S-U8fd-gqRwPcWXAXm8JwjL&confirm=t&uuid=f97d0410-9839-4646-b2ca-70254d763b1f\n","To: /content/data.zip\n","100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 423M/423M [00:01<00:00, 268MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["ğŸ“¦ Extracting...\n","ğŸ“ Final contents of data/: ['videos', 'labels', 'alignments']\n"]}],"source":["# Install gdown to download from Google Drive\n","!pip install -q gdown\n","\n","import os\n","import zipfile\n","import gdown\n","\n","# Google Drive file ID\n","file_id = \"1YlvpDLix3S-U8fd-gqRwPcWXAXm8JwjL\"\n","zip_path = \"data.zip\"\n","\n","# Download from Drive\n","print(\"â¬‡ï¸ Downloading data.zip from Google Drive...\")\n","gdown.download(id=file_id, output=zip_path, quiet=False)\n","\n","# Extract ZIP\n","print(\"ğŸ“¦ Extracting...\")\n","with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","    zip_ref.extractall(\".\")\n","\n","if os.path.exists(\"data/align\"):\n","    os.rename(\"data/align/s1\", \"data/labels\")\n","\n","# âœ… Rename s1 â†’ videos, align â†’ labels\n","if os.path.exists(\"data/s1\"):\n","    os.rename(\"data/s1\", \"data/videos\")\n","\n","\n","# Show structure\n","print(\"ğŸ“ Final contents of data/:\", os.listdir(\"data\"))\n"]},{"cell_type":"code","execution_count":null,"id":"63a39795","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":403},"id":"63a39795","executionInfo":{"status":"ok","timestamp":1753106040455,"user_tz":-330,"elapsed":30938,"user":{"displayName":"Priyanshul Thakur","userId":"11776131157483549665"}},"outputId":"fa24ec95-3698-4e5d-9f48-d96c314cd8b7"},"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸ“‚ Please upload the following project files:\n","- train_ctc.py\n","- utils.py\n","- decoder.py\n","- model.py\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-973b5503-5c02-4315-8a9f-e45ac601779b\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-973b5503-5c02-4315-8a9f-e45ac601779b\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving decoder.py to decoder.py\n","Saving lip_detector.py to lip_detector.py\n","Saving live_infer.py to live_infer.py\n","Saving model.py to model.py\n","Saving streamlit_app.py to streamlit_app.py\n","Saving train_ctc.py to train_ctc.py\n","Saving train_model.py to train_model.py\n","Saving utils.py to utils.py\n"]}],"source":["print(\"ğŸ“‚ Please upload the following project files:\")\n","print(\"- train_ctc.py\")\n","print(\"- utils.py\")\n","print(\"- decoder.py\")\n","print(\"- model.py\")\n","\n","from google.colab import files\n","uploaded_scripts = files.upload()\n"]},{"cell_type":"code","execution_count":null,"id":"0af40dcf","metadata":{"id":"0af40dcf"},"outputs":[],"source":["import shutil\n","os.makedirs(\"app\", exist_ok=True)\n","\n","for fname in [\"decoder.py\", \"model.py\"]:\n","    if fname in uploaded_scripts:\n","        shutil.move(fname, f\"app/{fname}\")\n"]},{"cell_type":"code","execution_count":null,"id":"c710c287","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c710c287","executionInfo":{"status":"ok","timestamp":1753113496573,"user_tz":-330,"elapsed":2,"user":{"displayName":"Priyanshul Thakur","userId":"11776131157483549665"}},"outputId":"6e6fdad9-09af-4191-80aa-5da4f12f9d16"},"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… Patched train_ctc.py for Colab paths\n"]}],"source":["with open(\"train_ctc.py\", \"r\") as f:\n","    code = f.read()\n","\n","code = code.replace(\"../data/videos\", \"data/videos\")\n","code = code.replace(\"../data/labels\", \"data/labels\")\n","\n","with open(\"train_ctc.py\", \"w\") as f:\n","    f.write(code)\n","\n","print(\"âœ… Patched train_ctc.py for Colab paths\")\n"]},{"cell_type":"code","source":["import shutil\n","shutil.move(\"app/model.py\", \"model.py\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"mAIemfZQpJIS","executionInfo":{"status":"ok","timestamp":1753112500003,"user_tz":-330,"elapsed":6,"user":{"displayName":"Priyanshul Thakur","userId":"11776131157483549665"}},"outputId":"7f88aa06-3f18-4d14-acab-be5a43f77443"},"id":"mAIemfZQpJIS","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'model.py'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["# ğŸ”§ Patch model.py to fix ctc_batch_cost import\n","model_path = \"model.py\"\n","\n","with open(model_path, \"r\") as file:\n","    code = file.read()\n","\n","code = code.replace(\n","    \"from keras.backend import ctc_batch_cost\",\n","    \"from tensorflow.keras.backend import ctc_batch_cost\"\n",")\n","\n","with open(model_path, \"w\") as file:\n","    file.write(code)\n","\n","print(\"âœ… Patched model.py to use TensorFlow's ctc_batch_cost\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qeaGKcOLpr6B","executionInfo":{"status":"ok","timestamp":1753112565499,"user_tz":-330,"elapsed":478,"user":{"displayName":"Priyanshul Thakur","userId":"11776131157483549665"}},"outputId":"dcf9f79f-cc45-4558-bcb3-d1b91c0acf06"},"id":"qeaGKcOLpr6B","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… Patched model.py to use TensorFlow's ctc_batch_cost\n"]}]},{"cell_type":"code","source":["import os\n","\n","if os.path.exists(\"data/alignments\"):\n","    os.rename(\"data/alignments\", \"data/labels\")\n","    print(\"âœ… Renamed data/alignments â†’ data/labels\")\n","else:\n","    print(\"âŒ Folder 'data/alignments' not found.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zhw7kQHXqRb_","executionInfo":{"status":"ok","timestamp":1753112852801,"user_tz":-330,"elapsed":417,"user":{"displayName":"Priyanshul Thakur","userId":"11776131157483549665"}},"outputId":"0401cfcf-0e8e-43de-d4be-1ea9140054a1"},"id":"Zhw7kQHXqRb_","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… Renamed data/alignments â†’ data/labels\n"]}]},{"cell_type":"code","source":["import os\n","\n","label_files = sorted(os.listdir(\"data/labels/s1\"))\n","print(f\"ğŸ“‚ Total .align files found: {len(label_files)}\")\n","print(\"ğŸ“ First few align files:\", label_files[:5])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zeczCKFgrAC-","executionInfo":{"status":"ok","timestamp":1753113570588,"user_tz":-330,"elapsed":672,"user":{"displayName":"Priyanshul Thakur","userId":"11776131157483549665"}},"outputId":"d1f2aaca-57ef-42ec-c8ae-8a068a6db2e6"},"id":"zeczCKFgrAC-","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸ“‚ Total .align files found: 1000\n","ğŸ“ First few align files: ['bbaf2n.align', 'bbaf3s.align', 'bbaf4p.align', 'bbaf5a.align', 'bbal6n.align']\n"]}]},{"cell_type":"code","source":["import os\n","\n","video_files = sorted(os.listdir(\"data/videos\"))\n","align_files = sorted(os.listdir(\"data/labels\"))\n","\n","video_basenames = [f.split(\".\")[0] for f in video_files if f.endswith(\".mpg\")]\n","align_basenames = [f.split(\".\")[0] for f in align_files if f.endswith(\".align\")]\n","\n","print(\"ğŸ¥ First 10 video basenames:\", video_basenames[:10])\n","print(\"ğŸ“„ First 10 align basenames:\", align_basenames[:10])\n","\n","# Now check how many match\n","matching = list(set(video_basenames) & set(align_basenames))\n","print(f\"âœ… Found {len(matching)} matching video-align pairs.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lDQG4n4ruBFW","executionInfo":{"status":"ok","timestamp":1753113699364,"user_tz":-330,"elapsed":4,"user":{"displayName":"Priyanshul Thakur","userId":"11776131157483549665"}},"outputId":"de552c8d-c043-4664-9db2-ae0fdb2750ca"},"id":"lDQG4n4ruBFW","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸ¥ First 10 video basenames: ['bbaf2n', 'bbaf3s', 'bbaf4p', 'bbaf5a', 'bbal6n', 'bbal7s', 'bbal8p', 'bbal9a', 'bbas1s', 'bbas2p']\n","ğŸ“„ First 10 align basenames: []\n","âœ… Found 0 matching video-align pairs.\n"]}]},{"cell_type":"code","source":["import os\n","\n","print(\"ğŸ” Sample files in 'data/labels':\")\n","print(os.listdir(\"data/labels\")[:10])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bY8-97ubuM9H","executionInfo":{"status":"ok","timestamp":1753113748148,"user_tz":-330,"elapsed":459,"user":{"displayName":"Priyanshul Thakur","userId":"11776131157483549665"}},"outputId":"62da1df7-191d-4555-d921-5676876d8b8e"},"id":"bY8-97ubuM9H","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸ” Sample files in 'data/labels':\n","['s1']\n"]}]},{"cell_type":"code","source":["import os\n","import shutil\n","\n","src_folder = \"data/labels/s1\"\n","dst_folder = \"data/labels\"\n","\n","moved = 0\n","for fname in os.listdir(src_folder):\n","    if fname.endswith(\".align\"):\n","        shutil.move(os.path.join(src_folder, fname), os.path.join(dst_folder, fname))\n","        moved += 1\n","\n","print(f\"âœ… Moved {moved} .align files from 'labels/s1' â†’ 'labels'\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8lX013I0uWoR","executionInfo":{"status":"ok","timestamp":1753113790266,"user_tz":-330,"elapsed":464,"user":{"displayName":"Priyanshul Thakur","userId":"11776131157483549665"}},"outputId":"73eb9110-5ab1-4dbc-ed9d-8cd9804b416e"},"id":"8lX013I0uWoR","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… Moved 1000 .align files from 'labels/s1' â†’ 'labels'\n"]}]},{"cell_type":"code","execution_count":null,"id":"e703dced","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e703dced","executionInfo":{"status":"ok","timestamp":1753114643709,"user_tz":-330,"elapsed":846620,"user":{"displayName":"Priyanshul Thakur","userId":"11776131157483549665"}},"outputId":"20a41ebc-87f9-4230-bcfc-1b0c909be3f8"},"outputs":[{"output_type":"stream","name":"stdout","text":["2025-07-21 16:03:17.673249: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1753113797.694659   33702 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1753113797.701351   33702 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2025-07-21 16:03:17.722260: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","[INFO] Loading data...\n","\u001b[0;36m[mpeg1video @ 0x26c00f00] \u001b[0m\u001b[1;31mac-tex damaged at 22 17\n","\u001b[0m\u001b[0;36m[mpeg1video @ 0x26c00f00] \u001b[0m\u001b[1;31mWarning MVs not available\n","\u001b[0m[INFO] Building model...\n","2025-07-21 16:03:55.818865: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","I0000 00:00:1753113835.821096   33702 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n","[INFO] Training model...\n","2025-07-21 16:03:58.016532: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1500000000 exceeds 10% of free system memory.\n","2025-07-21 16:03:59.416542: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1500000000 exceeds 10% of free system memory.\n","Epoch 1/10\n","I0000 00:00:1753113844.251777   34883 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","\u001b[1m500/500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 113ms/step - loss: 69.1862\n","Epoch 2/10\n","\u001b[1m500/500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 118ms/step - loss: 56.1386\n","Epoch 3/10\n","\u001b[1m500/500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 121ms/step - loss: 50.8938\n","Epoch 4/10\n","\u001b[1m500/500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 121ms/step - loss: 46.8308\n","Epoch 5/10\n","\u001b[1m500/500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 121ms/step - loss: 43.7963\n","Epoch 6/10\n","\u001b[1m500/500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 121ms/step - loss: 41.7373\n","Epoch 7/10\n","\u001b[1m500/500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 121ms/step - loss: 40.5638\n","Epoch 8/10\n","\u001b[1m500/500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 120ms/step - loss: 39.2857\n","Epoch 9/10\n","\u001b[1m500/500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 120ms/step - loss: 38.3809\n","Epoch 10/10\n","\u001b[1m500/500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 120ms/step - loss: 37.5705\n","WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","[INFO] Model saved to models/best_model.h5\n"]}],"source":["!python3 train_ctc.py\n"]},{"cell_type":"code","execution_count":null,"id":"6462561a","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":297},"id":"6462561a","executionInfo":{"status":"error","timestamp":1753105682234,"user_tz":-330,"elapsed":379,"user":{"displayName":"Priyanshul Thakur","userId":"11776131157483549665"}},"outputId":"242f4638-c852-4e80-d615-d983b0a74040"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"Cannot find file: models/best_model.h5","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-7-2415389337.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"models/best_model.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    231\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Cannot find file: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=undefined-variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m   \u001b[0mcomm_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_IPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomm_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: Cannot find file: models/best_model.h5"]}],"source":["from google.colab import files\n","files.download(\"models/best_model.h5\")\n"]},{"cell_type":"code","execution_count":null,"id":"bf0de7e9","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":90},"id":"bf0de7e9","executionInfo":{"status":"ok","timestamp":1753114731550,"user_tz":-330,"elapsed":32353,"user":{"displayName":"Priyanshul Thakur","userId":"11776131157483549665"}},"outputId":"4e2c9ca5-0395-4214-a87f-f0731e301c70"},"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸ“¹ Upload a .mpg video to test inference:\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-f04a6d6a-f02c-4c28-9751-93ccf1277997\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-f04a6d6a-f02c-4c28-9751-93ccf1277997\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving bbaf2n.mpg to bbaf2n.mpg\n"]}],"source":["print(\"ğŸ“¹ Upload a .mpg video to test inference:\")\n","from google.colab import files\n","video_upload = files.upload()\n","video_file = list(video_upload.keys())[0]\n"]},{"cell_type":"code","source":["# ğŸ”§ Build proper inference model using only video input and softmax output\n","from keras.models import Model\n","\n","# Step 1: Confirm which input is video (usually input[0])\n","video_input = model.input[0]\n","\n","# Step 2: Get the softmax layer correctly\n","# You can list all layers to confirm, but this usually works:\n","softmax_output = model.get_layer(\"y_pred\").output\n","\n","\n","# Step 3: Create a simplified inference model\n","inference_model = Model(inputs=video_input, outputs=softmax_output)\n"],"metadata":{"id":"uzfuPZDO0LA9"},"id":"uzfuPZDO0LA9","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"OImhIT910f-L"},"id":"OImhIT910f-L","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"68648136","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"68648136","executionInfo":{"status":"ok","timestamp":1753116330445,"user_tz":-330,"elapsed":1088,"user":{"displayName":"Priyanshul Thakur","userId":"11776131157483549665"}},"outputId":"165f4690-8cb0-467a-a743-d20216fa06ec"},"outputs":[{"output_type":"stream","name":"stdout","text":["[INFO] Loading charset and inference model...\n","[INFO] Loading and preprocessing video...\n","[INFO] Running inference...\n","\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 548ms/step\n","ğŸ—£ï¸ Predicted Text: let wr_e_ _t si_ lg_on\n"]}],"source":["from utils import load_video, preprocess_video\n","from decoder import greedy_decoder, get_charset\n","from model import build_ctc_model\n","\n","print(\"[INFO] Loading charset and inference model...\")\n","charset = get_charset()\n","output_dim = 28  # must match trained model\n","\n","# Build and load model\n","inference_model = build_ctc_model(input_dim=(75, 50, 100, 1), output_dim=output_dim, training=False)\n","inference_model.load_weights(\"models/best_model.h5\")\n","\n","# Load and preprocess video\n","print(\"[INFO] Loading and preprocessing video...\")\n","frames = load_video(open(video_file, 'rb'))\n","input_tensor = preprocess_video(frames)\n","\n","# Run inference\n","print(\"[INFO] Running inference...\")\n","pred = inference_model.predict(input_tensor)\n","\n","# Decode prediction\n","text = greedy_decoder(pred[0], charset)\n","print(\"ğŸ—£ï¸ Predicted Text:\", text)\n"]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}